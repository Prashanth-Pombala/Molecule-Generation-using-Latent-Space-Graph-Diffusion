{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zioGJQ7dn5IS",
        "outputId": "a340fa46-c970-4a39-9be7-1c16b033f3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.6-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n",
            "Downloading rdkit-2024.3.6-cp310-cp310-manylinux_2_28_x86_64.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.6\n",
            "2.5.0+cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_scatter-2.1.2%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt20cu117\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu117/torch_sparse-0.6.18%2Bpt20cu117-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt20cu117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install matplotlib\n",
        "!pip install rdkit\n",
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
        "\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data from the CSV and preprocessing it by removing the Hydrogen atoms, converting SMILES to Graph and one-hot encoding the Atom Type."
      ],
      "metadata": {
        "id": "YDQvVPjKBcZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7pHzoQnaWmJC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def edge_index_to_adj(edge_index, num_nodes):\n",
        "    # Create an empty adjacency matrix\n",
        "    adj = torch.zeros(num_nodes, num_nodes)\n",
        "\n",
        "    # Fill the adjacency matrix using the edge indices\n",
        "    adj[edge_index[0], edge_index[1]] = 1\n",
        "    adj[edge_index[1], edge_index[0]] = 1  # For undirected graphs, if edge (i,j) exists, edge (j,i) also exists\n",
        "\n",
        "    return adj\n",
        "\n",
        "\n",
        "def load_qm9_smiles(csv_file):\n",
        "    # Read the CSV file containing the QM9 dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Extract SMILES strings\n",
        "    smiles_list = df['smiles'].tolist()\n",
        "\n",
        "    return smiles_list\n",
        "\n",
        "\n",
        "csv_file = \"qm9.csv\"  # Replace with the path to your QM9 CSV file\n",
        "qm9_smiles = load_qm9_smiles(csv_file)\n",
        "\n",
        "def remove_hydrogen_from_smiles(smiles_list):\n",
        "    modified_smiles = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES:\", smiles)\n",
        "            continue\n",
        "        mol = Chem.RemoveHs(mol)\n",
        "        modified_smiles.append(Chem.MolToSmiles(mol))\n",
        "    return modified_smiles\n",
        "\n",
        "\n",
        "modified_smiles = remove_hydrogen_from_smiles(qm9_smiles)\n",
        "def smiles_to_graph(smiles):\n",
        "    # Parse the SMILES string\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None, None\n",
        "\n",
        "    # Get node features (atomic numbers)\n",
        "    atomic_numbers = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Get edge indices (connectivity)\n",
        "    edge_index = []\n",
        "    for bond in mol.GetBonds():\n",
        "        start_idx = bond.GetBeginAtomIdx()\n",
        "        end_idx = bond.GetEndAtomIdx()\n",
        "        edge_index.append([start_idx, end_idx])\n",
        "\n",
        "    # Convert edge indices to PyTorch tensor\n",
        "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "\n",
        "    # Convert node features to PyTorch tensor\n",
        "    node_features = torch.tensor(atomic_numbers, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    return node_features, edge_index\n",
        "\n",
        "\n",
        "filtered_dataset = []\n",
        "\n",
        "# Define encoding mappings\n",
        "encoding_mappings = {\n",
        "    7: [0, 0, 1, 0, 0],\n",
        "    8: [0, 0, 0, 1, 0],\n",
        "    6: [0, 1, 0, 0, 0],\n",
        "    9: [0, 0, 0, 0, 1]\n",
        "}\n",
        "\n",
        "# Iterate over modified SMILES\n",
        "for smile in modified_smiles:\n",
        "    try:\n",
        "        # Convert SMILES to graph representation\n",
        "        node_features, edge_index1 = smiles_to_graph(smile)\n",
        "\n",
        "\n",
        "        num_nodes = node_features.shape[0]\n",
        "        if num_nodes > 1:\n",
        "            # Convert node features to one-hot encoding\n",
        "            one_hot_encoded = torch.tensor([encoding_mappings[num.item()] for num in node_features], dtype=torch.float32)\n",
        "\n",
        "            # Create Data object and add it to the filtered dataset\n",
        "            graph = Data(x=one_hot_encoded, edge_index=edge_index1, num_nodes=num_nodes)\n",
        "            filtered_dataset.append(graph)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing SMILES: {smile}. {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the modules need for GNN"
      ],
      "metadata": {
        "id": "9ThI3AIAB1ps"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8bc1a81-5b99-4b6e-8091-a9d44f3142d3"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments, normalization_factor, aggregation_method: str):\n",
        "    \"\"\"Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
        "        Normalization: 'sum' or 'mean'.\n",
        "    \"\"\"\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    if aggregation_method == 'sum':\n",
        "        result = result / normalization_factor\n",
        "\n",
        "    if aggregation_method == 'mean':\n",
        "        norm = data.new_zeros(result.shape)\n",
        "        norm.scatter_add_(0, segment_ids, data.new_ones(data.shape))\n",
        "        norm[norm == 0] = 1\n",
        "        result = result / norm\n",
        "    return result\n",
        "\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, out_node_nf,aggregation_method='sum', device='cpu',\n",
        "                 act_fn=nn.SiLU(), n_layers=4, attention=False,\n",
        "                 normalization_factor=100, ):\n",
        "        super(GNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(\n",
        "                self.hidden_nf, self.hidden_nf, self.hidden_nf,\n",
        "                normalization_factor=normalization_factor,\n",
        "                aggregation_method=aggregation_method,\n",
        "                edges_in_d=in_edge_nf, act_fn=act_fn,\n",
        "                attention=attention))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, edges, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        h = self.embedding_out(h)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h\n",
        "import numpy as np\n",
        "\n",
        "def fully_connected_graph(num_nodes):\n",
        "    # Generate all possible pairs of nodes\n",
        "    nodes = np.arange(num_nodes)\n",
        "    pairs = np.array(np.meshgrid(nodes, nodes)).T.reshape(-1, 2)\n",
        "\n",
        "    # Filter out self-loops (optional, depending on your requirements)\n",
        "    pairs = pairs[pairs[:, 0] != pairs[:, 1]]\n",
        "\n",
        "    # Create the edge index tensor\n",
        "    edge_index = torch.tensor(pairs, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the modules needed For EGNN\n"
      ],
      "metadata": {
        "id": "zdmDQOoACD8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "06eaf32b-0b98-4070-89ba-45a1b13ea85d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def coord2diff(x, edge_index, norm_constant=1):\n",
        "    row, col = edge_index\n",
        "    coord_diff = x[row] - x[col]\n",
        "    radial = torch.sum((coord_diff) ** 2, 1).unsqueeze(1)\n",
        "    norm = torch.sqrt(radial + 1e-8)\n",
        "    coord_diff = coord_diff/(norm + norm_constant)\n",
        "    return radial, coord_diff\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "\n",
        "class EquivariantUpdate(nn.Module):\n",
        "    def __init__(self, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=1, act_fn=nn.SiLU(), tanh=False, coords_range=10.0):\n",
        "        super(EquivariantUpdate, self).__init__()\n",
        "        self.tanh = tanh\n",
        "        self.coords_range = coords_range\n",
        "        input_edge = hidden_nf * 2 + edges_in_d\n",
        "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "        self.coord_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn,\n",
        "            layer)\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "    def coord_model(self, h, coord, edge_index, coord_diff, edge_attr, edge_mask):\n",
        "        row, col = edge_index\n",
        "        input_tensor = torch.cat([h[row], h[col], edge_attr], dim=1)\n",
        "        if self.tanh:\n",
        "            trans = coord_diff * torch.tanh(self.coord_mlp(input_tensor)) * self.coords_range\n",
        "        else:\n",
        "            trans = coord_diff * self.coord_mlp(input_tensor)\n",
        "        if edge_mask is not None:\n",
        "            trans = trans * edge_mask\n",
        "        agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        coord = coord + agg\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, coord, edge_index, coord_diff, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        coord = self.coord_model(h, coord, edge_index, coord_diff, edge_attr, edge_mask)\n",
        "        if node_mask is not None:\n",
        "            coord = coord * node_mask\n",
        "        return coord\n",
        "\n",
        "\n",
        "class EquivariantBlock(nn.Module):\n",
        "    def __init__(self, hidden_nf, edge_feat_nf=2, device='cpu', act_fn=nn.SiLU(), n_layers=2, attention=True,\n",
        "                 norm_diff=True, tanh=False, coords_range=15, norm_constant=1, sin_embedding=None,\n",
        "                 normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EquivariantBlock, self).__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.norm_constant = norm_constant\n",
        "        self.sin_embedding = sin_embedding\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=edge_feat_nf,\n",
        "                                              act_fn=act_fn, attention=attention,\n",
        "                                              normalization_factor=self.normalization_factor,\n",
        "                                              aggregation_method=self.aggregation_method))\n",
        "        self.add_module(\"gcl_equiv\", EquivariantUpdate(hidden_nf, edges_in_d=edge_feat_nf, act_fn=nn.SiLU(), tanh=tanh,\n",
        "                                                       coords_range=self.coords_range_layer,\n",
        "                                                       normalization_factor=self.normalization_factor,\n",
        "                                                       aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None, edge_attr=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, coord_diff = coord2diff(x, edge_index, self.norm_constant)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        edge_attr = torch.cat([distances, edge_attr], dim=1)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edge_index, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        x = self._modules[\"gcl_equiv\"](h, x, edge_index, coord_diff, edge_attr, node_mask, edge_mask)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "class EGNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=3, attention=False,\n",
        "                 norm_diff=True, out_node_nf=None, tanh=False, coords_range=15, norm_constant=1, inv_sublayers=2,\n",
        "                 sin_embedding=False, normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EGNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range/n_layers) if n_layers > 0 else float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        if sin_embedding:\n",
        "            self.sin_embedding = SinusoidsEmbeddingNew()\n",
        "            edge_feat_nf = self.sin_embedding.dim * 2\n",
        "        else:\n",
        "            self.sin_embedding = None\n",
        "            edge_feat_nf = 2\n",
        "\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"e_block_%d\" % i, EquivariantBlock(hidden_nf, edge_feat_nf=edge_feat_nf, device=device,\n",
        "                                                               act_fn=act_fn, n_layers=inv_sublayers,\n",
        "                                                               attention=attention, norm_diff=norm_diff, tanh=tanh,\n",
        "                                                               coords_range=coords_range, norm_constant=norm_constant,\n",
        "                                                               sin_embedding=self.sin_embedding,\n",
        "                                                               normalization_factor=self.normalization_factor,\n",
        "                                                               aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, _ = coord2diff(x, edge_index)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, x = self._modules[\"e_block_%d\" % i](h, x, edge_index, node_mask=node_mask, edge_mask=edge_mask, edge_attr=distances)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        h = self.embedding_out(h)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fully_connected_graph_with_self_loops(num_nodes):\n",
        "    \"\"\"\n",
        "    Generates edge indices for a fully connected graph with self-loops.\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Edge indices of the fully connected graph with self-loops.\n",
        "    \"\"\"\n",
        "    # Create edge indices for a fully connected graph with self-loops\n",
        "    edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes)])\n",
        "\n",
        "    return edge_index.t().contiguous()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Autoencoder Model\n"
      ],
      "metadata": {
        "id": "db9KyZNUCPdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNAConv\n",
        "# Initialize the autoencoder model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "   def __init__(self):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        n_layers= 4\n",
        "        in_edge_nf = 0\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        act_fn = torch.nn.SiLU()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1 = GNN(\n",
        "                    in_node_nf=5,\n",
        "                    in_edge_nf=in_edge_nf,\n",
        "                    hidden_nf=8,\n",
        "                    out_node_nf= 1,\n",
        "                    device=device,\n",
        "                    act_fn=act_fn,\n",
        "                    n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dconv1 = GNN(\n",
        "                    in_node_nf=1,\n",
        "                    in_edge_nf=in_edge_nf,\n",
        "                    hidden_nf=8,\n",
        "                    out_node_nf= 5,\n",
        "                    device=device,\n",
        "                    act_fn=act_fn,\n",
        "                    n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "   def encode(self,x,edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "   def decode(self, z, edge_index):\n",
        "        z = self.dconv1(z, edge_index)\n",
        "\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "model= GraphAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "87U73ur9pMvt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Autoencoder Model\n"
      ],
      "metadata": {
        "id": "bRAhau3SCVIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import pickle\n",
        "epochs =10\n",
        "data1= filtered_dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    total_loss1 = 0\n",
        "    total_loss2 = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "        adjacency_matrix_1 = torch.zeros((num_nodes_1, num_nodes_1), dtype=torch.int)\n",
        "        for i in range(edge_index_1.size(1)):\n",
        "            source_node_1 = edge_index_1[0, i].item()\n",
        "            target_node_1 = edge_index_1[1, i].item()\n",
        "            adjacency_matrix_1[source_node_1, target_node_1] = 1\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, -1, pairwise_distances_1)\n",
        "\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "        num_repeats_1 = 5\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "\n",
        "        num_vectors = data.x.size(0)\n",
        "        num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "        matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors):\n",
        "            for j in range(i + 1, num_vectors):\n",
        "                matrix[i,num_vectors+ k] = 1\n",
        "                matrix[j,num_vectors+ k] = 1\n",
        "                matrix[num_vectors+ k,i] = 1\n",
        "                matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "        adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "        num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "        updated_edge_index = [[], []]\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if adjacency_matrix[i, j] == 1:\n",
        "                    updated_edge_index[0].append(i)\n",
        "                    updated_edge_index[1].append(j)\n",
        "\n",
        "\n",
        "        edge_index = torch.tensor(updated_edge_index)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        updated_node_features_1 = updated_node_features_1.to(device)\n",
        "        edge_index = edge_index.to(device)\n",
        "\n",
        "        x = model.encode(updated_node_features_1, edge_index)\n",
        "\n",
        "        x= torch.exp(x)\n",
        "        seed= x\n",
        "\n",
        "        v=x.to(device)\n",
        "\n",
        "        d= model.decode(v,edge_index)\n",
        "        d=d.unsqueeze(0)\n",
        "        updated_node_features_1= updated_node_features_1.unsqueeze(0)\n",
        "        loss1= criterion(updated_node_features_1,d)\n",
        "\n",
        "\n",
        "        mean = torch.mean(seed, dim=0)\n",
        "\n",
        "\n",
        "        std = torch.std(seed, dim=0)\n",
        "        q_mu= mean\n",
        "        q_sigma= std\n",
        "        p_mu= torch.zeros_like(q_mu)+20\n",
        "\n",
        "        p_sigma= torch.ones_like(q_sigma)*4\n",
        "\n",
        "\n",
        "        kl_distance_h =(\n",
        "                torch.log(p_sigma / (q_sigma + 1e-8) + 1e-8)\n",
        "                + 0.5 * (q_sigma**2 + (q_mu - p_mu)**2) / (p_sigma**2)\n",
        "                - 0.5\n",
        "            )\n",
        "        kl= kl_distance_h.reshape(kl_distance_h.size(0), -1).sum(dim=-1)\n",
        "        kl= torch.sum(kl ,dim=0)\n",
        "        loss2=0.01*kl\n",
        "\n",
        "\n",
        "        loss=loss1+loss2\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_loss1 += loss1.item()\n",
        "        total_loss2 += loss2.item()\n",
        "\n",
        "    average_loss = total_loss /len(data1)\n",
        "    average_loss1 = total_loss1 /len(data1)\n",
        "    average_loss2 = total_loss2 /len(data1)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss1: {average_loss1:.4f}\")\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss2: {average_loss2:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "    with open(f'heat_encoder_model_epoch_{epoch + 1}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "        print(f\"Model saved for epoch {epoch + 1}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lYGXQ5ycCADV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwcxAZjjXjkM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('LOAD_YOUR_BEST_HEAT_AUTOENCODER_MODEL', 'rb') as f:\n",
        "    loaded_auto = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from os.path import join as pjoin\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from einops import repeat, rearrange\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, Image\n",
        "from matplotlib.animation import FuncAnimation"
      ],
      "metadata": {
        "id": "bwOoA6oh0mJ4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JFHU_2hFvAFs"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def dct(x, norm=None):\n",
        "    \"\"\"\n",
        "    Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last dimension\n",
        "    \"\"\"\n",
        "    x_shape = x.shape\n",
        "    N = x_shape[-1]\n",
        "    x = x.contiguous().view(-1, N)\n",
        "\n",
        "    v = torch.cat([x[:, ::2], x[:, 1::2].flip([1])], dim=1)\n",
        "\n",
        "    #Vc = torch.fft.rfft(v, 1)\n",
        "    Vc = torch.view_as_real(torch.fft.fft(v, dim=1))\n",
        "\n",
        "    k = - torch.arange(N, dtype=x.dtype,\n",
        "                       device=x.device)[None, :] * np.pi / (2 * N)\n",
        "    W_r = torch.cos(k)\n",
        "    W_i = torch.sin(k)\n",
        "\n",
        "    V = Vc[:, :, 0] * W_r - Vc[:, :, 1] * W_i\n",
        "\n",
        "    if norm == 'ortho':\n",
        "        V[:, 0] /= np.sqrt(N) * 2\n",
        "        V[:, 1:] /= np.sqrt(N / 2) * 2\n",
        "\n",
        "    V = 2 * V.view(*x_shape)\n",
        "\n",
        "    return V\n",
        "\n",
        "\n",
        "def idct(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct(dct(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the inverse DCT-II of the signal over the last dimension\n",
        "    \"\"\"\n",
        "\n",
        "    x_shape = X.shape\n",
        "    N = x_shape[-1]\n",
        "\n",
        "    X_v = X.contiguous().view(-1, x_shape[-1]) / 2\n",
        "\n",
        "    if norm == 'ortho':\n",
        "        X_v[:, 0] *= np.sqrt(N) * 2\n",
        "        X_v[:, 1:] *= np.sqrt(N / 2) * 2\n",
        "\n",
        "    k = torch.arange(x_shape[-1], dtype=X.dtype,\n",
        "                     device=X.device)[None, :] * np.pi / (2 * N)\n",
        "    W_r = torch.cos(k)\n",
        "    W_i = torch.sin(k)\n",
        "\n",
        "    V_t_r = X_v\n",
        "    V_t_i = torch.cat([X_v[:, :1] * 0, -X_v.flip([1])[:, :-1]], dim=1)\n",
        "\n",
        "    V_r = V_t_r * W_r - V_t_i * W_i\n",
        "    V_i = V_t_r * W_i + V_t_i * W_r\n",
        "\n",
        "    V = torch.cat([V_r.unsqueeze(2), V_i.unsqueeze(2)], dim=2)\n",
        "\n",
        "    #v = torch.fft.irfft(V, 1)\n",
        "    v = torch.fft.irfft(torch.view_as_complex(V), n=V.shape[1], dim=1)\n",
        "    x = v.new_zeros(v.shape)\n",
        "    x[:, ::2] += v[:, :N - (N // 2)]\n",
        "    x[:, 1::2] += v.flip([1])[:, :N // 2]\n",
        "\n",
        "    return x.view(*x_shape)\n",
        "\n",
        "\n",
        "def dct_2d(x, norm=None):\n",
        "    \"\"\"\n",
        "    2-dimentional Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 2 dimensions\n",
        "    \"\"\"\n",
        "    X1 = dct(x, norm=norm)\n",
        "    X2 = dct(X1.transpose(-1, -2), norm=norm)\n",
        "    return X2.transpose(-1, -2)\n",
        "\n",
        "\n",
        "def idct_2d(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to 2D DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct_2d(dct_2d(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 2 dimensions\n",
        "    \"\"\"\n",
        "    x1 = idct(X, norm=norm)\n",
        "    x2 = idct(x1.transpose(-1, -2), norm=norm)\n",
        "    return x2.transpose(-1, -2)\n",
        "\n",
        "\n",
        "def dct_3d(x, norm=None):\n",
        "    \"\"\"\n",
        "    3-dimentional Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 3 dimensions\n",
        "    \"\"\"\n",
        "    X1 = dct(x, norm=norm)\n",
        "    X2 = dct(X1.transpose(-1, -2), norm=norm)\n",
        "    X3 = dct(X2.transpose(-1, -3), norm=norm)\n",
        "    return X3.transpose(-1, -3).transpose(-1, -2)\n",
        "\n",
        "\n",
        "def idct_3d(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to 3D DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct_3d(dct_3d(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 3 dimensions\n",
        "    \"\"\"\n",
        "    x1 = idct(X, norm=norm)\n",
        "    x2 = idct(x1.transpose(-1, -2), norm=norm)\n",
        "    x3 = idct(x2.transpose(-1, -3), norm=norm)\n",
        "    return x3.transpose(-1, -3).transpose(-1, -2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blur_sigma_max =1\n",
        "\n",
        "blur_sigma_min = 0.2\n",
        "blur_schedule = np.exp(np.linspace(np.log(blur_sigma_min), np.log(blur_sigma_max),100))\n",
        "#blur_schedule = np.array([0] + list(blur_schedule))\n",
        "device='cpu'\n"
      ],
      "metadata": {
        "id": "f_IW0c-LZGae"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ckl95q6Kei6m"
      },
      "outputs": [],
      "source": [
        "class DCTBlur1D(nn.Module):\n",
        "\n",
        "    def __init__(self, blur_sigmas, device):\n",
        "        super().__init__()\n",
        "        self.blur_sigmas = torch.tensor(blur_sigmas).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x,img, fwd_steps):\n",
        "        freqs = np.pi*torch.linspace(0, img-1, img)/img\n",
        "        frequencies_squared = freqs[None, :]**2\n",
        "        if len(x.shape) == 4:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None, None, None]\n",
        "        elif len(x.shape) == 3:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None, None]\n",
        "        elif len(x.shape) == 2:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None]\n",
        "        t = sigmas**2/2\n",
        "        dct_coefs = dct(x, norm='ortho')\n",
        "        dct_coefs = dct_coefs * torch.exp(- frequencies_squared * t)\n",
        "        return idct(dct_coefs, norm='ortho')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = DCTBlur1D(blur_schedule, device)"
      ],
      "metadata": {
        "id": "sDsPOa2LZGc8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the reverse heat model"
      ],
      "metadata": {
        "id": "DpEdEs2UFvUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ogfNn-k3nIFw"
      },
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float32)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "# Assume you have input features, edge_index, and edge_attr tensors\n",
        "in_node_nf = 1# Replace with the actual input node feature dimension\n",
        "out_node_nf = 1\n",
        "in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "hidden_nf = 4# Replace with the desired hidden dimension\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "act_fn = torch.nn.SiLU()\n",
        "n_layers = 4 # Replace with the desired number of layers\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the GNN model\n",
        "model = GNN(\n",
        "    in_node_nf=in_node_nf,\n",
        "    in_edge_nf=in_edge_nf,\n",
        "    hidden_nf=hidden_nf,\n",
        "    out_node_nf= out_node_nf,\n",
        "    device=device,\n",
        "    act_fn=act_fn,\n",
        "    n_layers=n_layers\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse Heat Training\n"
      ],
      "metadata": {
        "id": "hvGhbA0ZF1FX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG9tuUXB8gew"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "epochs =50\n",
        "data1= filtered_dataset\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        random_integer = random.randint(1, 98)\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "        adjacency_matrix_1 = torch.zeros((num_nodes_1, num_nodes_1), dtype=torch.int)\n",
        "        for i in range(edge_index_1.size(1)):\n",
        "            source_node_1 = edge_index_1[0, i].item()\n",
        "            target_node_1 = edge_index_1[1, i].item()\n",
        "            adjacency_matrix_1[source_node_1, target_node_1] = 1\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, -1, pairwise_distances_1)\n",
        "\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "\n",
        "        num_repeats_1 = 5\n",
        "\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "        num_vectors = data.x.size(0)\n",
        "        num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "        matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors):\n",
        "            for j in range(i + 1, num_vectors):\n",
        "                matrix[i,num_vectors+ k] = 1\n",
        "                matrix[j,num_vectors+ k] = 1\n",
        "                matrix[num_vectors+ k,i] = 1\n",
        "                matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "        adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "        num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "\n",
        "        updated_edge_index = [[], []]\n",
        "\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if adjacency_matrix[i, j] == 1:\n",
        "                    updated_edge_index[0].append(i)  # Source node\n",
        "                    updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "\n",
        "        edge_index = torch.tensor(updated_edge_index)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        updated_node_features_1 = updated_node_features_1.to(device)\n",
        "        edge_index = edge_index.to(device)\n",
        "\n",
        "        x = loaded_auto.encode(updated_node_features_1, edge_index)\n",
        "        x= torch.exp(x)\n",
        "\n",
        "\n",
        "\n",
        "        dat = torch.squeeze(x)\n",
        "\n",
        "        fwd_steps = torch.linspace(1, 99,99, dtype=torch.long, device=device)\n",
        "\n",
        "        blurred_batch =  mod(repeat(dat, 'd -> N d', N=99),num_nodes,fwd_steps).float()\n",
        "        blurred= blurred_batch[random_integer]\n",
        "\n",
        "        less_blurred= blurred_batch[random_integer-1]\n",
        "        sigma=0.01\n",
        "        noise = torch.randn_like(blurred) * sigma\n",
        "        perturbed_data = noise + blurred\n",
        "        pert =perturbed_data .unsqueeze(1)\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes).to(device)\n",
        "\n",
        "        output = model(pert, edge_index1)\n",
        "\n",
        "        diff= torch.squeeze(output)\n",
        "\n",
        "        prediction = perturbed_data + diff\n",
        "\n",
        "        loss = F.mse_loss(less_blurred,prediction)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss /len(data1)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "    with open(f'reverse_heat_model_epoch_{epoch + 1}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "        print(f\"Model saved for epoch {epoch + 1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best model"
      ],
      "metadata": {
        "id": "JkP0DVm3GTPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  'LOAD_YOUR_BEST_REVERSE_HEAT_MODEL_HERE'.pkl'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_heat = pickle.load(file)"
      ],
      "metadata": {
        "id": "SQWRzJaS6ZlQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Bond Type Predictor Model"
      ],
      "metadata": {
        "id": "QEoIooHSHP0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hTrsLBdayxAD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, GATConv, MessagePassing\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class BondTypePredictor(nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the BondTypePredictor model.\n",
        "\n",
        "        Args:\n",
        "            num_node_features (int): Number of input features for each node.\n",
        "            hidden_dim (int): Dimension of hidden layers in GNN.\n",
        "            num_classes (int): Number of bond types to predict.\n",
        "        \"\"\"\n",
        "        super(BondTypePredictor, self).__init__()\n",
        "\n",
        "        # GNN Layers to process the molecular graph\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "\n",
        "        self.edge_classifier = nn.Sequential(\n",
        "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Node feature matrix of shape [num_nodes, num_node_features].\n",
        "            edge_index (torch.Tensor): Edge index matrix of shape [2, num_edges].\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Predicted bond types for each edge of shape [num_edges, num_classes].\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        row, col = edge_index\n",
        "        edge_representation = torch.cat([x[row], x[col]], dim=1)\n",
        "\n",
        "\n",
        "        bond_type_logits = self.edge_classifier(edge_representation)\n",
        "\n",
        "        return bond_type_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VsNbsdK6dTFN"
      },
      "outputs": [],
      "source": [
        "with open('EDGE_TYPE_PREDICTOR_MODEL.pkl', 'rb') as f:\n",
        "    edge_type= pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sampling"
      ],
      "metadata": {
        "id": "VXjqh93kGk7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from rdkit import Chem\n",
        "\n",
        "deblur = []\n",
        "smiles_list = []\n",
        "\n",
        "for index in range(100):\n",
        "    ind= 9000+index# enter your dataset range for sampling\n",
        "\n",
        "    data = filtered_dataset[ind]\n",
        "    num_nodes = data.x.size(0)\n",
        "    K = 100\n",
        "\n",
        "    edge_index_1 = data.edge_index\n",
        "    node_features_1 = data.x\n",
        "    num_nodes_1 = node_features_1.size(0)\n",
        "    adjacency_matrix_1 = torch.zeros((num_nodes_1, num_nodes_1), dtype=torch.int)\n",
        "\n",
        "    for i in range(edge_index_1.size(1)):\n",
        "        source_node_1 = edge_index_1[0, i].item()\n",
        "        target_node_1 = edge_index_1[1, i].item()\n",
        "        adjacency_matrix_1[source_node_1, target_node_1] = 1\n",
        "\n",
        "    num_vectors_1 = node_features_1.size(0)\n",
        "    num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "    pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    for i in range(num_vectors_1):\n",
        "        for j in range(i + 1, num_vectors_1):\n",
        "            pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "            k += 1\n",
        "\n",
        "    pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "    pairwise_distances_1 = torch.where(pairwise_distances_1 == 0, -1, pairwise_distances_1)\n",
        "\n",
        "\n",
        "    column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "    num_repeats_1 = 5\n",
        "\n",
        "    row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "    updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "    num_vectors = data.x.size(0)\n",
        "    num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "    matrix = torch.zeros(num_vectors + num_upper_triangle_terms, num_vectors + num_upper_triangle_terms)\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            matrix[i, num_vectors + k] = 1\n",
        "            matrix[j, num_vectors + k] = 1\n",
        "            matrix[num_vectors + k, i] = 1\n",
        "            matrix[num_vectors + k, j] = 1\n",
        "            k += 1\n",
        "\n",
        "\n",
        "    adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "    num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "\n",
        "    updated_edge_index = [[], []]\n",
        "\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if adjacency_matrix[i, j] == 1:\n",
        "                updated_edge_index[0].append(i)\n",
        "                updated_edge_index[1].append(j)\n",
        "\n",
        "\n",
        "    edge_index1 = torch.tensor(updated_edge_index)\n",
        "\n",
        "    updated_node_features_1 = updated_node_features_1.to(device)\n",
        "    edge_index1 = edge_index1.to(device)\n",
        "\n",
        "    x = loaded_auto.encode(updated_node_features_1, edge_index1)\n",
        "    x = torch.exp(x)\n",
        "\n",
        "    dat = torch.squeeze(x)\n",
        "\n",
        "    fwd_steps = torch.linspace(1, 99, 99, dtype=torch.long, device=device)\n",
        "    initial_batch = mod(repeat(dat, 'd -> N d', N=99), num_nodes, fwd_steps).float()\n",
        "    initial_sample = initial_batch[90]\n",
        "    noises = [torch.randn_like(initial_sample[0], dtype=torch.float)[None] for _ in range(K)]\n",
        "    intermediate_samples_out = []\n",
        "    u = initial_sample.to(device).float()\n",
        "    intermediate_samples_out = []\n",
        "\n",
        "    for i in range(K, 0, -1):\n",
        "        edge_index = fully_connected_graph_with_self_loops(num_nodes).to(device)\n",
        "        pert = u.unsqueeze(1)\n",
        "\n",
        "        output = loaded_heat(pert, edge_index)\n",
        "        u_mean = torch.squeeze(output) + u\n",
        "        noise = noises[i - 1]\n",
        "        u = u_mean + noise * 0.0125\n",
        "        deblur.append(u)\n",
        "\n",
        "    final = torch.unsqueeze(u, 1)\n",
        "    recon = loaded_auto.decode(final.to(device), edge_index1)\n",
        "\n",
        "    des = recon[:num_vectors]\n",
        "    ans = des[:, :5]\n",
        "\n",
        "\n",
        "    max_values, _ = torch.max(ans, dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "    ans_binary = torch.where(ans == max_values, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "\n",
        "    row_values = []\n",
        "\n",
        "\n",
        "    for row in ans_binary:\n",
        "        binary_str = ''.join([str(int(x)) for x in row.tolist()])\n",
        "        if binary_str == '01000':\n",
        "            row_values.append(6)\n",
        "        elif binary_str == '10000':\n",
        "            row_values.append(1)\n",
        "        elif binary_str == '00100':\n",
        "            row_values.append(7)\n",
        "        elif binary_str == '00010':\n",
        "            row_values.append(8)\n",
        "        elif binary_str == '00001':\n",
        "            row_values.append(9)\n",
        "        else:\n",
        "            row_values.append(0)\n",
        "\n",
        "\n",
        "    new_tensor = torch.tensor(row_values)\n",
        "\n",
        "    augmented_features_matrix = recon\n",
        "\n",
        "\n",
        "    node_features_matrix = augmented_features_matrix[:num_vectors, :]\n",
        "    edge_features_matrix = augmented_features_matrix[num_vectors:, :]  # Extract edge features\n",
        "    row_averages = torch.mean(edge_features_matrix, dim=1)\n",
        "    row_averages = (row_averages > 0).float()\n",
        "\n",
        "\n",
        "    adjacency_matrix_dec = torch.zeros((num_vectors, num_vectors), dtype=torch.int)\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            adjacency_matrix_dec[i][j] = row_averages[k]\n",
        "            adjacency_matrix_dec[j][i] = row_averages[k]\n",
        "            k += 1\n",
        "\n",
        "\n",
        "    edge_list = [(i, j) for i in range(adjacency_matrix_dec.size(0)) for j in range(adjacency_matrix_dec.size(1)) if adjacency_matrix_dec[i][j] != 0]\n",
        "\n",
        "\n",
        "    edge_index = torch.tensor(edge_list).t().contiguous()\n",
        "\n",
        "    if edge_index.dim() < 2 or edge_index.size(1) == 0:\n",
        "\n",
        "        edge_attr = torch.empty(0, dtype=torch.long)\n",
        "\n",
        "    else:\n",
        "\n",
        "        bond_type_logits = edge_type(ans_binary[:, :5], edge_index)\n",
        "\n",
        "\n",
        "        edge_attr = torch.argmax(bond_type_logits, dim=1)  # Shape: [num_edges]\n",
        "\n",
        "\n",
        "    import torch\n",
        "    from rdkit import Chem\n",
        "\n",
        "    # Assuming 'data' is your graph representation with 'data.x' for node features and 'data.edge_index' for edge connections\n",
        "    # You need to convert your graph to an RDKit Mol object first\n",
        "    mol = Chem.RWMol()\n",
        "\n",
        "    # Define the mapping from integer bond type to RDKit bond type\n",
        "    bond_type_mapping = {\n",
        "        1: Chem.BondType.SINGLE,\n",
        "        2: Chem.BondType.DOUBLE,\n",
        "        3: Chem.BondType.TRIPLE,\n",
        "        4: Chem.BondType.AROMATIC\n",
        "    }\n",
        "\n",
        "    # Keep track of the bonds already added to avoid duplicates\n",
        "    added_bonds = set()\n",
        "\n",
        "    # Add atoms to the molecule based on node features (data.x)\n",
        "    for atom_type in new_tensor:\n",
        "        atom = Chem.Atom(atom_type.item())\n",
        "        mol.AddAtom(atom)\n",
        "\n",
        "    # Add bonds to the molecule based on edge connections (edge_index) and edge types (edge_attr)\n",
        "    for (i, j), bond_type in zip(edge_index.t().tolist(), edge_attr.tolist()):\n",
        "        # Check if the bond already exists\n",
        "        if (i, j) not in added_bonds:\n",
        "            # Get the appropriate RDKit bond type based on bond_type\n",
        "            rdkit_bond_type = bond_type_mapping.get(bond_type, Chem.BondType.SINGLE)  # Default to SINGLE if bond_type is unknown\n",
        "\n",
        "            # Add the bond to the molecule with the specified bond type\n",
        "            mol.AddBond(i, j, rdkit_bond_type)\n",
        "\n",
        "            # Mark this bond as added to avoid duplicates\n",
        "            added_bonds.add((i, j))\n",
        "            added_bonds.add((j, i))  # Assuming the graph is undirected\n",
        "\n",
        "    # Convert the RDKit Mol object to a SMILES string\n",
        "    smiles = Chem.MolToSmiles(mol)\n",
        "    generated_smiles = smiles\n",
        "    smiles_list.append(generated_smiles)\n",
        "\n",
        "\n",
        "    # Check if the molecule is valid\n",
        "    def is_valid_molecule(mol):\n",
        "        if mol is None:\n",
        "            return False\n",
        "        return Chem.SanitizeMol(mol) == Chem.SanitizeFlags.SANITIZE_NONE\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    valid = is_valid_molecule(mol)\n",
        "\n"
      ],
      "metadata": {
        "id": "oHca9O7ctVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the Validity, Uniqueness and Novelty\n"
      ],
      "metadata": {
        "id": "btHaswjaHcYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-yFcvZRa6T3"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "\n",
        "def is_valid_smiles(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return mol is not None\n",
        "\n",
        "\n",
        "def get_largest_fragment(mol):\n",
        "    mol_frags = Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
        "    largest_frag = max(mol_frags, key=lambda m: m.GetNumAtoms(), default=None)\n",
        "    return Chem.MolToSmiles(largest_frag) if largest_frag else None\n",
        "\n",
        "# Function to check and count the number of valid SMILES\n",
        "def count_valid_smiles(smiles_list):\n",
        "    valid_smiles = []\n",
        "    fragmented_smiles = []\n",
        "\n",
        "    for smiles in smiles_list:\n",
        "        if is_valid_smiles(smiles):\n",
        "            valid_smiles.append(smiles)\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            largest_fragment_smile = get_largest_fragment(mol)\n",
        "            if largest_fragment_smile:\n",
        "                fragmented_smiles.append(largest_fragment_smile)\n",
        "\n",
        "\n",
        "    print(f\"VALID SMILES : {fragmented_smiles}\")\n",
        "    print(f\"Number of VALID SMILES: {len(fragmented_smiles)}\")\n",
        "\n",
        "    return fragmented_smiles\n",
        "\n",
        "\n",
        "def find_unique_smiles(generated_smiles):\n",
        "    smiles_count = {}\n",
        "\n",
        "    # Count occurrences of each SMILES\n",
        "    for smiles in generated_smiles:\n",
        "        if smiles in smiles_count:\n",
        "            smiles_count[smiles] += 1\n",
        "        else:\n",
        "            smiles_count[smiles] = 1\n",
        "\n",
        "    # Collect SMILES that appear only once\n",
        "    unique_smiles = [smiles for smiles, count in smiles_count.items() if count == 1]\n",
        "\n",
        "    return unique_smiles\n",
        "\n",
        "# Function to find unique SMILES not in the dataset\n",
        "def find_novel_smiles(generated_smiles, dataset):\n",
        "    novel_smiles = []\n",
        "    for smiles in generated_smiles:\n",
        "        if smiles not in dataset:  # Check if the SMILES is not in the dataset\n",
        "            novel_smiles.append(smiles)\n",
        "    return novel_smiles\n",
        "\n",
        "\n",
        "fragmented_smiles = count_valid_smiles(smiles_list)\n",
        "\n",
        "# Find and print the unique SMILES in the fragmented list\n",
        "unique_smiles = find_unique_smiles(fragmented_smiles)\n",
        "print(f\"Number of unique SMILES generated: {len(unique_smiles)}\")\n",
        "print(f\"Percetage of unique SMILES generated: {len(unique_smiles)/len(fragmented_smiles)}\")\n",
        "\n",
        "\n",
        "# Find and print the novel SMILES not in the dataset\n",
        "novel_smiles = find_novel_smiles(unique_smiles, modified_smiles)\n",
        "print(f\"Novel SMILES not in dataset: {novel_smiles}\")\n",
        "print(f\"Number of novel SMILES not in dataset: {len(novel_smiles)}\")\n",
        "print(f\"novelty: {len(novel_smiles)/len(unique_smiles)}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}