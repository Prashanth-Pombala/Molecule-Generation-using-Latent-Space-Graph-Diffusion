{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zioGJQ7dn5IS",
        "outputId": "460cb62c-adbf-4fac-de6a-27ebad1e3e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (10.4.0)\n",
            "2.5.0+cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt20cu117)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt20cu117)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric\n",
        "!pip install matplotlib\n",
        "!pip install rdkit\n",
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-2.0.1+cu117.html\n",
        "\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data from the CSV and preprocessing it by removing the Hydrogen atoms, converting SMILES to Graph and one-hot encoding the Atom Type."
      ],
      "metadata": {
        "id": "YDQvVPjKBcZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7pHzoQnaWmJC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def edge_index_to_adj(edge_index, num_nodes):\n",
        "    # Create an empty adjacency matrix\n",
        "    adj = torch.zeros(num_nodes, num_nodes)\n",
        "\n",
        "    # Fill the adjacency matrix using the edge indices\n",
        "    adj[edge_index[0], edge_index[1]] = 1\n",
        "    adj[edge_index[1], edge_index[0]] = 1  # For undirected graphs, if edge (i,j) exists, edge (j,i) also exists\n",
        "\n",
        "    return adj\n",
        "\n",
        "\n",
        "def load_qm9_smiles(csv_file):\n",
        "    # Read the CSV file containing the QM9 dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Extract SMILES strings\n",
        "    smiles_list = df['smiles'].tolist()\n",
        "\n",
        "    return smiles_list\n",
        "\n",
        "\n",
        "csv_file = \"qm9.csv\"  # Replace with the path to your QM9 CSV file\n",
        "qm9_smiles = load_qm9_smiles(csv_file)\n",
        "\n",
        "def remove_hydrogen_from_smiles(smiles_list):\n",
        "    modified_smiles = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES:\", smiles)\n",
        "            continue\n",
        "        mol = Chem.RemoveHs(mol)\n",
        "        modified_smiles.append(Chem.MolToSmiles(mol))\n",
        "    return modified_smiles\n",
        "\n",
        "\n",
        "modified_smiles = remove_hydrogen_from_smiles(qm9_smiles)\n",
        "def smiles_to_graph(smiles):\n",
        "    # Parse the SMILES string\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None, None\n",
        "\n",
        "    # Get node features (atomic numbers)\n",
        "    atomic_numbers = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Get edge indices (connectivity)\n",
        "    edge_index = []\n",
        "    for bond in mol.GetBonds():\n",
        "        start_idx = bond.GetBeginAtomIdx()\n",
        "        end_idx = bond.GetEndAtomIdx()\n",
        "        edge_index.append([start_idx, end_idx])\n",
        "\n",
        "    # Convert edge indices to PyTorch tensor\n",
        "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "\n",
        "    # Convert node features to PyTorch tensor\n",
        "    node_features = torch.tensor(atomic_numbers, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    return node_features, edge_index\n",
        "\n",
        "\n",
        "filtered_dataset = []\n",
        "\n",
        "# Define encoding mappings\n",
        "encoding_mappings = {\n",
        "    7: [0, 0, 1, 0, 0],\n",
        "    8: [0, 0, 0, 1, 0],\n",
        "    6: [0, 1, 0, 0, 0],\n",
        "    9: [0, 0, 0, 0, 1]\n",
        "}\n",
        "\n",
        "# Iterate over modified SMILES\n",
        "for smile in modified_smiles:\n",
        "    try:\n",
        "        # Convert SMILES to graph representation\n",
        "        node_features, edge_index1 = smiles_to_graph(smile)\n",
        "\n",
        "\n",
        "        num_nodes = node_features.shape[0]\n",
        "        if num_nodes > 1:\n",
        "            # Convert node features to one-hot encoding\n",
        "            one_hot_encoded = torch.tensor([encoding_mappings[num.item()] for num in node_features], dtype=torch.float32)\n",
        "\n",
        "            # Create Data object and add it to the filtered dataset\n",
        "            graph = Data(x=one_hot_encoded, edge_index=edge_index1, num_nodes=num_nodes)\n",
        "            filtered_dataset.append(graph)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing SMILES: {smile}. {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the modules need for GNN"
      ],
      "metadata": {
        "id": "9ThI3AIAB1ps"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8bc1a81-5b99-4b6e-8091-a9d44f3142d3"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments, normalization_factor, aggregation_method: str):\n",
        "    \"\"\"Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
        "        Normalization: 'sum' or 'mean'.\n",
        "    \"\"\"\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    if aggregation_method == 'sum':\n",
        "        result = result / normalization_factor\n",
        "\n",
        "    if aggregation_method == 'mean':\n",
        "        norm = data.new_zeros(result.shape)\n",
        "        norm.scatter_add_(0, segment_ids, data.new_ones(data.shape))\n",
        "        norm[norm == 0] = 1\n",
        "        result = result / norm\n",
        "    return result\n",
        "\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, out_node_nf,aggregation_method='sum', device='cpu',\n",
        "                 act_fn=nn.SiLU(), n_layers=4, attention=False,\n",
        "                 normalization_factor=100, ):\n",
        "        super(GNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(\n",
        "                self.hidden_nf, self.hidden_nf, self.hidden_nf,\n",
        "                normalization_factor=normalization_factor,\n",
        "                aggregation_method=aggregation_method,\n",
        "                edges_in_d=in_edge_nf, act_fn=act_fn,\n",
        "                attention=attention))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, edges, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        h = self.embedding_out(h)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h\n",
        "import numpy as np\n",
        "\n",
        "def fully_connected_graph(num_nodes):\n",
        "    # Generate all possible pairs of nodes\n",
        "    nodes = np.arange(num_nodes)\n",
        "    pairs = np.array(np.meshgrid(nodes, nodes)).T.reshape(-1, 2)\n",
        "\n",
        "    # Filter out self-loops (optional, depending on your requirements)\n",
        "    pairs = pairs[pairs[:, 0] != pairs[:, 1]]\n",
        "\n",
        "    # Create the edge index tensor\n",
        "    edge_index = torch.tensor(pairs, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the modules needed for EGNN\n"
      ],
      "metadata": {
        "id": "zdmDQOoACD8A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "06eaf32b-0b98-4070-89ba-45a1b13ea85d"
      },
      "outputs": [],
      "source": [
        "\n",
        "def coord2diff(x, edge_index, norm_constant=1):\n",
        "    row, col = edge_index\n",
        "    coord_diff = x[row] - x[col]\n",
        "    radial = torch.sum((coord_diff) ** 2, 1).unsqueeze(1)\n",
        "    norm = torch.sqrt(radial + 1e-8)\n",
        "    coord_diff = coord_diff/(norm + norm_constant)\n",
        "    return radial, coord_diff\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "\n",
        "class EquivariantUpdate(nn.Module):\n",
        "    def __init__(self, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=1, act_fn=nn.SiLU(), tanh=False, coords_range=10.0):\n",
        "        super(EquivariantUpdate, self).__init__()\n",
        "        self.tanh = tanh\n",
        "        self.coords_range = coords_range\n",
        "        input_edge = hidden_nf * 2 + edges_in_d\n",
        "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "        self.coord_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn,\n",
        "            layer)\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "    def coord_model(self, h, coord, edge_index, coord_diff, edge_attr, edge_mask):\n",
        "        row, col = edge_index\n",
        "        input_tensor = torch.cat([h[row], h[col], edge_attr], dim=1)\n",
        "        if self.tanh:\n",
        "            trans = coord_diff * torch.tanh(self.coord_mlp(input_tensor)) * self.coords_range\n",
        "        else:\n",
        "            trans = coord_diff * self.coord_mlp(input_tensor)\n",
        "        if edge_mask is not None:\n",
        "            trans = trans * edge_mask\n",
        "        agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        coord = coord + agg\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, coord, edge_index, coord_diff, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        coord = self.coord_model(h, coord, edge_index, coord_diff, edge_attr, edge_mask)\n",
        "        if node_mask is not None:\n",
        "            coord = coord * node_mask\n",
        "        return coord\n",
        "\n",
        "\n",
        "class EquivariantBlock(nn.Module):\n",
        "    def __init__(self, hidden_nf, edge_feat_nf=2, device='cpu', act_fn=nn.SiLU(), n_layers=2, attention=True,\n",
        "                 norm_diff=True, tanh=False, coords_range=15, norm_constant=1, sin_embedding=None,\n",
        "                 normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EquivariantBlock, self).__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.norm_constant = norm_constant\n",
        "        self.sin_embedding = sin_embedding\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=edge_feat_nf,\n",
        "                                              act_fn=act_fn, attention=attention,\n",
        "                                              normalization_factor=self.normalization_factor,\n",
        "                                              aggregation_method=self.aggregation_method))\n",
        "        self.add_module(\"gcl_equiv\", EquivariantUpdate(hidden_nf, edges_in_d=edge_feat_nf, act_fn=nn.SiLU(), tanh=tanh,\n",
        "                                                       coords_range=self.coords_range_layer,\n",
        "                                                       normalization_factor=self.normalization_factor,\n",
        "                                                       aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None, edge_attr=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, coord_diff = coord2diff(x, edge_index, self.norm_constant)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        edge_attr = torch.cat([distances, edge_attr], dim=1)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edge_index, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        x = self._modules[\"gcl_equiv\"](h, x, edge_index, coord_diff, edge_attr, node_mask, edge_mask)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "class EGNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=3, attention=False,\n",
        "                 norm_diff=True, out_node_nf=None, tanh=False, coords_range=15, norm_constant=1, inv_sublayers=2,\n",
        "                 sin_embedding=False, normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EGNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range/n_layers) if n_layers > 0 else float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        if sin_embedding:\n",
        "            self.sin_embedding = SinusoidsEmbeddingNew()\n",
        "            edge_feat_nf = self.sin_embedding.dim * 2\n",
        "        else:\n",
        "            self.sin_embedding = None\n",
        "            edge_feat_nf = 2\n",
        "\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"e_block_%d\" % i, EquivariantBlock(hidden_nf, edge_feat_nf=edge_feat_nf, device=device,\n",
        "                                                               act_fn=act_fn, n_layers=inv_sublayers,\n",
        "                                                               attention=attention, norm_diff=norm_diff, tanh=tanh,\n",
        "                                                               coords_range=coords_range, norm_constant=norm_constant,\n",
        "                                                               sin_embedding=self.sin_embedding,\n",
        "                                                               normalization_factor=self.normalization_factor,\n",
        "                                                               aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, _ = coord2diff(x, edge_index)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, x = self._modules[\"e_block_%d\" % i](h, x, edge_index, node_mask=node_mask, edge_mask=edge_mask, edge_attr=distances)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        h = self.embedding_out(h)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fully_connected_graph_with_self_loops(num_nodes):\n",
        "    \"\"\"\n",
        "    Generates edge indices for a fully connected graph with self-loops.\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Edge indices of the fully connected graph with self-loops.\n",
        "    \"\"\"\n",
        "    # Create edge indices for a fully connected graph with self-loops\n",
        "    edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes)])\n",
        "\n",
        "    return edge_index.t().contiguous()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating the degree for PNA"
      ],
      "metadata": {
        "id": "7T3OZxKtCLeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3cYGSYzOpMs3"
      },
      "outputs": [],
      "source": [
        "# Compute the maximum in-degree in the training data.\n",
        "max_degree = -1\n",
        "for data in filtered_dataset:\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "# Compute the in-degree histogram tensor\n",
        "deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
        "for data in filtered_dataset:\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Autoencoder"
      ],
      "metadata": {
        "id": "tRWKXJHjyGIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FuToEym1OVL8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNA\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "\n",
        "        # Define the parameters for the autoencoder\n",
        "\n",
        "        in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        act_fn = torch.nn.SiLU()\n",
        "        n_layers = 4  # Replace with the desired number of layers\n",
        "\n",
        "\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 =  PNA(\n",
        "            in_channels=5,\n",
        "            hidden_channels= 10,\n",
        "\n",
        "            out_channels=6,\n",
        "            num_layers=2,\n",
        "            aggregators=aggregators,\n",
        "            scalers=scalers,\n",
        "            deg=deg,\n",
        "            towers=1,\n",
        "\n",
        "            post_layers=1,\n",
        "            pre_layers=1\n",
        "        )\n",
        "\n",
        "        self.dconv1 = PNA(\n",
        "            in_channels=6,\n",
        "            hidden_channels= 10,\n",
        "            out_channels=5,\n",
        "            num_layers=2,\n",
        "            aggregators=aggregators,\n",
        "            scalers=scalers,\n",
        "            deg=deg,\n",
        "            towers=1,\n",
        "\n",
        "            post_layers=1,\n",
        "            pre_layers=1\n",
        "        )\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        z = self.dconv1(z, edge_index)\n",
        "\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model= GraphAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Autoencoder\n"
      ],
      "metadata": {
        "id": "-PzT9W1uyKqu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gSEPN-43kxD"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pickle\n",
        "\n",
        "\n",
        "for epoch in range(20):\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(epoch)\n",
        "    for data in filtered_dataset:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x[:,:5]\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "\n",
        "        adjacency_matrix_1 = edge_index_to_adj(edge_index_1, num_nodes_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "        # Calculate pairwise distances\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, 1, pairwise_distances_1*0)\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "        num_repeats_1 = 5\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z = model.encode(node_features_1,data.edge_index)\n",
        "\n",
        "        vectors = z\n",
        "\n",
        "\n",
        "        # Initialize an empty matrix to store pairwise distances\n",
        "        num_vectors = vectors.size(0)\n",
        "        num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "        matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "        pairwise_distances = torch.zeros(num_upper_triangle_terms)\n",
        "\n",
        "        k= 0\n",
        "        # Calculate pairwise distances\n",
        "        for i in range(num_vectors):\n",
        "            for j in range(i + 1, num_vectors):\n",
        "                matrix[i,num_vectors+ k] = 1\n",
        "                matrix[j,num_vectors+ k] = 1\n",
        "                matrix[num_vectors+ k,i] = 1\n",
        "                matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "                distance = torch.norm(vectors[i] - vectors[j])\n",
        "\n",
        "                pairwise_distances[k] = distance\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "        pairwise_distances = pairwise_distances.view(-1, 1)\n",
        "\n",
        "        column_tensor = pairwise_distances\n",
        "\n",
        "        num_repeats = 6\n",
        "\n",
        "        row_tensor = column_tensor.repeat(1, num_repeats)\n",
        "\n",
        "        updated_node_features = torch.cat([z, row_tensor], dim=0)\n",
        "\n",
        "        adjacency_matrix = matrix\n",
        "        num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "        updated_edge_index = [[], []]\n",
        "\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if adjacency_matrix[i, j] == 1:\n",
        "                    updated_edge_index[0].append(i)  # Source node\n",
        "                    updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "\n",
        "        edge_index = torch.tensor(updated_edge_index)\n",
        "\n",
        "\n",
        "        recon = model.decode(updated_node_features, edge_index)\n",
        "\n",
        "        loss = criterion(recon, updated_node_features_1)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss /len( filtered_dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "    with open(f'EGNN_2D_model_epoch_{epoch + 1}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "        print(f\"Model saved for epoch {epoch + 1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Atom Autoencoder"
      ],
      "metadata": {
        "id": "YkLpZzKHDKMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWsLdTJ9Y8qw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNAConv\n",
        "\n",
        "class nodeAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(nodeAutoencoder, self).__init__()\n",
        "\n",
        "        # Define the parameters for the autoencoder\n",
        "\n",
        "        in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        act_fn = torch.nn.SiLU()\n",
        "        n_layers = 4  # Replace with the desired number of layers\n",
        "\n",
        "\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1 = PNAConv(in_channels=5, out_channels=2,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.dconv1 = PNAConv(in_channels=2, out_channels=5,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        z = self.dconv1(z, edge_index)\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "# Define other necessary components and hyperparameters\n",
        "epochs = 20\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model= nodeAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training  the Atom Autoencoder"
      ],
      "metadata": {
        "id": "jJZOmtcsDWb6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT432VkHYaEo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "data1=filtered_dataset\n",
        "for epoch in range(10):\n",
        "    start_time = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "    for data in data1:\n",
        "\n",
        "        edge_index_1 = data.edge_index.to(device)\n",
        "\n",
        "        feat = data.x.to(device)\n",
        "\n",
        "        num_nodes_1 = feat.size(0)\n",
        "\n",
        "        adjacency_matrix_1 = edge_index_to_adj(edge_index_1, num_nodes_1)\n",
        "\n",
        "        node_features_1= feat[:,:5]\n",
        "\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z =model.encode(node_features_1,edge_index_1.to(device)) #encode\n",
        "\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes_1)\n",
        "\n",
        "        recon = model.decode(z.to(device), edge_index1.to(device))\n",
        "\n",
        "\n",
        "        num_rows2 = recon.size(0)\n",
        "\n",
        "\n",
        "        loss = criterion(recon,node_features_1)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "    average_loss = total_loss / len(data1)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "    with open(f'Atom_encoder_model_epoch_{epoch + 1}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "        print(f\"Model saved for epoch {epoch + 1}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the best model from the trained models"
      ],
      "metadata": {
        "id": "FfLvbPM8Vsr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwcxAZjjXjkM"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('LOAD_YOUR_BEST_AUTOENCODER_MODEL_HERE', 'rb') as f:\n",
        "    loaded_auto = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5pG8ggvynaL"
      },
      "outputs": [],
      "source": [
        "with open('LOAD_YOUR_BEST_ATOM_AUTOENCODER_HERE', 'rb') as f:\n",
        "    loaded_node = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the parameters for Diffusion"
      ],
      "metadata": {
        "id": "tMaM-yMiGw0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79e25c3e-440f-487a-9408-7493d1955330"
      },
      "outputs": [],
      "source": [
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0.0001, 0.9999)\n",
        "\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "def quadratic_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
        "\n",
        "def sigmoid_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(-6, 6, timesteps)\n",
        "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cd33fca-0fde-4955-b1b7-953e2b8e6e57"
      },
      "outputs": [],
      "source": [
        "timesteps = 50\n",
        "\n",
        "# define beta schedule\n",
        "betas = linear_beta_schedule(timesteps=timesteps)\n",
        "\n",
        "\n",
        "# define alphas\n",
        "alphas = 1. - betas\n",
        "\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    batch_size = t.shape[0]\n",
        "    out = a.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcbFKhHY4pXA"
      },
      "outputs": [],
      "source": [
        "# forward diffusion\n",
        "def q_sample(x_start, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
        "    )\n",
        "\n",
        "    return sqrt_alphas_cumprod_t.to(device) * x_start.to(device) + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_RqmHQd4pZh"
      },
      "outputs": [],
      "source": [
        "def get_noisy_image(x_start, t):\n",
        "\n",
        "  x_noisy,tar_noise = q_sample(x_start, t=t)\n",
        "  return x_noisy,tar_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the restoration Model"
      ],
      "metadata": {
        "id": "PkUWFlWUHA7U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVtY_afBPAUL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "# Assume you have input features, edge_index, and edge_attr tensors\n",
        "in_node_nf = 1 # Replace with the actual input node feature dimension\n",
        "in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "hidden_nf = 64 # Replace with the desired hidden dimension\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "act_fn = torch.nn.SiLU()\n",
        "n_layers = 7  # Replace with the desired number of layers\n",
        "\n",
        "# Create a simple graph data\n",
        "\n",
        "\n",
        "# Instantiate the EGNN model\n",
        "model = EGNN(\n",
        "    in_node_nf=in_node_nf,\n",
        "    in_edge_nf=in_edge_nf,\n",
        "    hidden_nf=hidden_nf,\n",
        "    device=device,\n",
        "    act_fn=act_fn,\n",
        "    n_layers=n_layers\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Restoration Model\n"
      ],
      "metadata": {
        "id": "IeLfu5Cky9bd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztgTofaNX3RI"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "epochs =20\n",
        "data1= filtered_dataset\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x[:,:5]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        node= node_features_1[:,:5]\n",
        "\n",
        "        z = loaded_auto.encode(node_features_1, edge_index_1)\n",
        "        y= loaded_node.encode(node,edge_index_1.to(device))\n",
        "        x= torch.cat([z,y ], dim=1)\n",
        "        v=x.to(device)\n",
        "\n",
        "        random_timestep = torch.randint(1, 50, size=(1,))\n",
        "\n",
        "        t = torch.tensor([random_timestep])\n",
        "        h_time = torch.empty_like(x[:, 0:1]).fill_(t.item()/50)\n",
        "\n",
        "        original_tensor = x\n",
        "\n",
        "        ans,tar_noise= get_noisy_image(original_tensor, t)\n",
        "\n",
        "        num_nodes1=ans.shape[0]\n",
        "\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes1).to(device)\n",
        "\n",
        "        g,output = model(h_time,ans, edge_index1)\n",
        "        new_z= output-ans\n",
        "\n",
        "        loss= criterion(new_z, tar_noise)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    average_loss = total_loss /len( filtered_dataset)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "    with open(f'EGNN_2D_diffusion_model_epoch_{epoch + 1}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "        print(f\"Model saved for epoch {epoch + 1}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the restoration model"
      ],
      "metadata": {
        "id": "KXWtugueWBa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfoiAoxpKkEX"
      },
      "outputs": [],
      "source": [
        "with open('LOAD_YOUR_BEST_DIFFUSION_MODEL_HERE', 'rb') as f:\n",
        "    loaded_deno = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing elements for Sampling"
      ],
      "metadata": {
        "id": "_f36F1K3HLPh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S90DC1f_7vTJ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import operator\n",
        "from itertools import chain, product\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Any, Optional, Callable, Tuple, Dict, Sequence, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor, LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#come here\n",
        "@torch.no_grad()\n",
        "def p_sample(model, data, t, t_index):\n",
        "    t1 = t_index\n",
        "    h_time = torch.empty_like(data[:, 0:1]).fill_(t1/100)\n",
        "    # Concatenate h and h_time along dimension 1\n",
        "    ans = data\n",
        "\n",
        "\n",
        "    num_nodes1=ans.shape[0]\n",
        "    edge_index1 = fully_connected_graph(num_nodes1).to(device)\n",
        "    s= torch.cat([ans,h_time ], dim=1)\n",
        "\n",
        "    g,output = loaded_deno(h_time,ans, edge_index1)\n",
        "    new_z= output-ans\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    betas_t = extract(betas, t, ans.shape)\n",
        "\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t,ans.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, ans.shape)\n",
        "\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        ans - betas_t * new_z / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, ans.shape)\n",
        "        noise = torch.randn_like(ans)\n",
        "\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model,data):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = 1\n",
        "\n",
        "    t_init= torch.tensor([49])\n",
        "    imgs = []\n",
        "    features,tar= get_noisy_image(data, t_init)\n",
        "\n",
        "\n",
        "    for i in tqdm(reversed(range(0, 50)), desc='sampling loop time step', total=50):\n",
        "\n",
        "\n",
        "        data = p_sample(model, data, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "\n",
        "        imgs.append(data.cpu().numpy())\n",
        "\n",
        "    return imgs\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, data):\n",
        "    return p_sample_loop(model, data)"
      ],
      "metadata": {
        "id": "bpg8UeNvUn0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the Bond Type Predictor Model"
      ],
      "metadata": {
        "id": "QEoIooHSHP0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTrsLBdayxAD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, GATConv, MessagePassing\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "class BondTypePredictor(nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim, num_classes):\n",
        "        \"\"\"\n",
        "        Initialize the BondTypePredictor model.\n",
        "\n",
        "        Args:\n",
        "            num_node_features (int): Number of input features for each node.\n",
        "            hidden_dim (int): Dimension of hidden layers in GNN.\n",
        "            num_classes (int): Number of bond types to predict.\n",
        "        \"\"\"\n",
        "        super(BondTypePredictor, self).__init__()\n",
        "\n",
        "        # GNN Layers to process the molecular graph\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
        "\n",
        "\n",
        "        self.edge_classifier = nn.Sequential(\n",
        "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Forward pass of the model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Node feature matrix of shape [num_nodes, num_node_features].\n",
        "            edge_index (torch.Tensor): Edge index matrix of shape [2, num_edges].\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Predicted bond types for each edge of shape [num_edges, num_classes].\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        row, col = edge_index\n",
        "        edge_representation = torch.cat([x[row], x[col]], dim=1)\n",
        "\n",
        "\n",
        "        bond_type_logits = self.edge_classifier(edge_representation)\n",
        "\n",
        "        return bond_type_logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsNbsdK6dTFN"
      },
      "outputs": [],
      "source": [
        "with open('LOAD_YOUR_BEST_BOND_TYPE_PREDICTION_MODEL', 'rb') as f:\n",
        "    edge_type= pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sampling process"
      ],
      "metadata": {
        "id": "tAgB2nY4HXE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ywPx101Un_X"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "smiles_list = []\n",
        "for i in range(100):\n",
        "\n",
        "\n",
        "    random_number = random.randint(2, 8)\n",
        "\n",
        "    real_num=random_number\n",
        "\n",
        "    num_vectors=real_num\n",
        "    num_vectors = real_num\n",
        "\n",
        "    edge_index1 =fully_connected_graph_with_self_loops(num_vectors)\n",
        "\n",
        "\n",
        "    data2=torch.randn(num_vectors,8).to(device)\n",
        "\n",
        "    samples = sample(model, data2)\n",
        "    final=samples[49]\n",
        "    final=torch.tensor(final)\n",
        "    latent= final[:, :6]\n",
        "\n",
        "    z= latent\n",
        "\n",
        "    vectors = z\n",
        "\n",
        "    num_vectors = vectors.size(0)\n",
        "    num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "    matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "    pairwise_distances = torch.zeros(num_upper_triangle_terms)\n",
        "\n",
        "    k= 0\n",
        "    # Calculate pairwise distances\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            matrix[i,num_vectors+ k] = 1\n",
        "            matrix[j,num_vectors+ k] = 1\n",
        "            matrix[num_vectors+ k,i] = 1\n",
        "            matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "            distance = torch.norm(vectors[i] - vectors[j])\n",
        "\n",
        "            pairwise_distances[k] = distance\n",
        "            k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    pairwise_distances = pairwise_distances.view(-1, 1)\n",
        "\n",
        "\n",
        "    column_tensor = pairwise_distances\n",
        "\n",
        "    num_repeats = 6\n",
        "\n",
        "    row_tensor = column_tensor.repeat(1, num_repeats)\n",
        "\n",
        "\n",
        "    updated_node_features = torch.cat([z, row_tensor], dim=0)\n",
        "\n",
        "    adjacency_matrix = matrix\n",
        "\n",
        "    num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "    updated_edge_index = [[], []]\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if adjacency_matrix[i, j] == 1:\n",
        "                updated_edge_index[0].append(i)  # Source node\n",
        "                updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "    edge_index = torch.tensor(updated_edge_index)\n",
        "\n",
        "    recon = loaded_auto.decode(updated_node_features, edge_index)\n",
        "    node = final[:, -2:]\n",
        "    node_out = loaded_node.decode(node.to(device), edge_index1.to(device))\n",
        "\n",
        "    des= recon[:num_vectors]\n",
        "\n",
        "    ans= node_out\n",
        "\n",
        "    max_values, _ = torch.max(ans, dim=1, keepdim=True)\n",
        "\n",
        "    ans_binary = torch.where(ans == max_values, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "    row_values = []\n",
        "\n",
        "    for row in ans_binary:\n",
        "\n",
        "        binary_str = ''.join([str(int(x)) for x in row.tolist()])\n",
        "\n",
        "        if binary_str == '01000':\n",
        "            row_values.append(6)\n",
        "        elif binary_str == '10000':\n",
        "            row_values.append(1)\n",
        "        elif binary_str == '00100':\n",
        "            row_values.append(7)\n",
        "        elif binary_str == '00010':\n",
        "            row_values.append(8)\n",
        "        elif binary_str == '00001':\n",
        "            row_values.append(9)\n",
        "        else:\n",
        "\n",
        "            row_values.append(0)\n",
        "\n",
        "\n",
        "    new_tensor = torch.tensor(row_values)\n",
        "\n",
        "    augmented_features_matrix = recon\n",
        "\n",
        "    node_features_matrix = augmented_features_matrix[:num_vectors, :]\n",
        "    edge_features_matrix = augmented_features_matrix[num_vectors:, :]\n",
        "    row_averages = torch.mean(edge_features_matrix, dim=1)\n",
        "    row_averages = (row_averages > 0).float()\n",
        "\n",
        "    adjacency_matrix_dec = torch.zeros((num_vectors, num_vectors), dtype=torch.int)\n",
        "\n",
        "    k= 0\n",
        "    # Calculate pairwise distances\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            adjacency_matrix_dec[i][j]=row_averages[k]\n",
        "            adjacency_matrix_dec[j][i]=row_averages[k]\n",
        "\n",
        "\n",
        "\n",
        "            k=k+ 1\n",
        "\n",
        "    edge_list = [(i, j) for i in range(adjacency_matrix_dec.size(0)) for j in range(adjacency_matrix_dec.size(1)) if adjacency_matrix_dec[i][j] != 0]\n",
        "\n",
        "    edge_index = torch.tensor(edge_list).t().contiguous()\n",
        "    if edge_index.dim() < 2 or edge_index.size(1) == 0:\n",
        "\n",
        "        edge_attr = torch.empty(0, dtype=torch.long)\n",
        "\n",
        "    else:\n",
        "    # If edges are present, run the bond type prediction\n",
        "        bond_type_logits = edge_type(ans_binary[:, :5], edge_index)\n",
        "\n",
        "    # Get the predicted bond type for each edge\n",
        "        edge_attr = torch.argmax(bond_type_logits, dim=1)  # Shape: [num_edges]\n",
        "\n",
        "\n",
        "    import torch\n",
        "    from rdkit import Chem\n",
        "\n",
        "    # Assuming 'data' is your graph representation with 'data.x' for node features and 'data.edge_index' for edge connections\n",
        "    # You need to convert your graph to an RDKit Mol object first\n",
        "    mol = Chem.RWMol()\n",
        "\n",
        "    # Define the mapping from integer bond type to RDKit bond type\n",
        "    bond_type_mapping = {\n",
        "        1: Chem.BondType.SINGLE,\n",
        "        2: Chem.BondType.DOUBLE,\n",
        "        3: Chem.BondType.TRIPLE,\n",
        "        4: Chem.BondType.AROMATIC\n",
        "    }\n",
        "\n",
        "    # Keep track of the bonds already added to avoid duplicates\n",
        "    added_bonds = set()\n",
        "\n",
        "    # Add atoms to the molecule based on node features (data.x)\n",
        "    for atom_type in new_tensor:\n",
        "        atom = Chem.Atom(atom_type.item())\n",
        "        mol.AddAtom(atom)\n",
        "\n",
        "    # Add bonds to the molecule based on edge connections (edge_index) and edge types (edge_attr)\n",
        "    for (i, j), bond_type in zip(edge_index.t().tolist(), edge_attr.tolist()):\n",
        "        # Check if the bond already exists\n",
        "        if (i, j) not in added_bonds:\n",
        "            # Get the appropriate RDKit bond type based on bond_type\n",
        "            rdkit_bond_type = bond_type_mapping.get(bond_type, Chem.BondType.SINGLE)  # Default to SINGLE if bond_type is unknown\n",
        "\n",
        "            # Add the bond to the molecule with the specified bond type\n",
        "            mol.AddBond(i, j, rdkit_bond_type)\n",
        "\n",
        "            # Mark this bond as added to avoid duplicates\n",
        "            added_bonds.add((i, j))\n",
        "            added_bonds.add((j, i))  # Assuming the graph is undirected\n",
        "\n",
        "    # Convert the RDKit Mol object to a SMILES string\n",
        "    smiles = Chem.MolToSmiles(mol)\n",
        "    generated_smiles = smiles\n",
        "    smiles_list.append(generated_smiles)\n",
        "\n",
        "\n",
        "\n",
        "    # Check if the molecule is valid (i.e., if it has correct atom types, valence, etc.)\n",
        "    def is_valid_molecule(mol):\n",
        "        if mol is None:\n",
        "            return False\n",
        "        return Chem.SanitizeMol(mol) == Chem.SanitizeFlags.SANITIZE_NONE\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    valid = is_valid_molecule(mol)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing the Validity, Uniqueness and Novelty\n"
      ],
      "metadata": {
        "id": "btHaswjaHcYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-yFcvZRa6T3"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "\n",
        "def is_valid_smiles(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return mol is not None\n",
        "\n",
        "\n",
        "def get_largest_fragment(mol):\n",
        "    mol_frags = Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
        "    largest_frag = max(mol_frags, key=lambda m: m.GetNumAtoms(), default=None)\n",
        "    return Chem.MolToSmiles(largest_frag) if largest_frag else None\n",
        "\n",
        "# Function to check and count the number of valid SMILES\n",
        "def count_valid_smiles(smiles_list):\n",
        "    valid_smiles = []\n",
        "    fragmented_smiles = []\n",
        "\n",
        "    for smiles in smiles_list:\n",
        "        if is_valid_smiles(smiles):\n",
        "            valid_smiles.append(smiles)\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            largest_fragment_smile = get_largest_fragment(mol)\n",
        "            if largest_fragment_smile:\n",
        "                fragmented_smiles.append(largest_fragment_smile)\n",
        "\n",
        "\n",
        "    print(f\"VALID SMILES : {fragmented_smiles}\")\n",
        "    print(f\"Number of VALID SMILES: {len(fragmented_smiles)}\")\n",
        "\n",
        "    return fragmented_smiles\n",
        "\n",
        "\n",
        "def find_unique_smiles(generated_smiles):\n",
        "    smiles_count = {}\n",
        "\n",
        "    # Count occurrences of each SMILES\n",
        "    for smiles in generated_smiles:\n",
        "        if smiles in smiles_count:\n",
        "            smiles_count[smiles] += 1\n",
        "        else:\n",
        "            smiles_count[smiles] = 1\n",
        "\n",
        "    # Collect SMILES that appear only once\n",
        "    unique_smiles = [smiles for smiles, count in smiles_count.items() if count == 1]\n",
        "\n",
        "    return unique_smiles\n",
        "\n",
        "# Function to find unique SMILES not in the dataset\n",
        "def find_novel_smiles(generated_smiles, dataset):\n",
        "    novel_smiles = []\n",
        "    for smiles in generated_smiles:\n",
        "        if smiles not in dataset:  # Check if the SMILES is not in the dataset\n",
        "            novel_smiles.append(smiles)\n",
        "    return novel_smiles\n",
        "\n",
        "\n",
        "fragmented_smiles = count_valid_smiles(smiles_list)\n",
        "\n",
        "# Find and print the unique SMILES in the fragmented list\n",
        "unique_smiles = find_unique_smiles(fragmented_smiles)\n",
        "print(f\"Number of unique SMILES generated: {len(unique_smiles)}\")\n",
        "print(f\"Percetage of unique SMILES generated: {len(unique_smiles)/len(fragmented_smiles)}\")\n",
        "\n",
        "\n",
        "# Find and print the novel SMILES not in the dataset\n",
        "novel_smiles = find_novel_smiles(unique_smiles, modified_smiles)\n",
        "print(f\"Novel SMILES not in dataset: {novel_smiles}\")\n",
        "print(f\"Number of novel SMILES not in dataset: {len(novel_smiles)}\")\n",
        "print(f\"novelty: {len(novel_smiles)/len(unique_smiles)}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}